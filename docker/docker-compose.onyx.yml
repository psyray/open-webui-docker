# Onyx stack with Onyx Craft (Option A - pre-built images only)
# Ref: https://docs.onyx.app/deployment/local/docker
# Merged with main compose: docker compose -f docker/docker-compose.yml -f docker/docker-compose.onyx.yml up -d

x-onyx-env: &onyx-env
  POSTGRES_HOST: relational_db
  VESPA_HOST: index
  REDIS_HOST: cache
  MODEL_SERVER_HOST: inference_model_server
  INDEXING_MODEL_SERVER_HOST: indexing_model_server
  INTERNAL_URL: http://api_server:8080
  FILE_STORE_BACKEND: postgres
  ENABLE_CRAFT: "true"
  AUTH_TYPE: basic
  POSTGRES_USER: postgres
  POSTGRES_PASSWORD: ${ONYX_POSTGRES_PASSWORD:-password}
  S3_ENDPOINT_URL: ""
  S3_AWS_ACCESS_KEY_ID: ""
  S3_AWS_SECRET_ACCESS_KEY: ""

services:
  relational_db:
    image: postgres:15.2-alpine
    container_name: onyx-db
    command: -c 'max_connections=250'
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${ONYX_POSTGRES_PASSWORD:-password}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - onyx_db:/var/lib/postgresql/data
    networks:
      - ollama-network
    restart: unless-stopped

  index:
    image: vespaengine/vespa:8.609.39
    container_name: onyx-index
    environment:
      VESPA_SKIP_UPGRADE_CHECK: "true"
    volumes:
      - onyx_vespa:/opt/vespa/var
    networks:
      - ollama-network
    restart: unless-stopped

  cache:
    image: redis:7.4-alpine
    container_name: onyx-cache
    command: redis-server --save "" --appendonly no
    tmpfs:
      - /data
    networks:
      - ollama-network
    restart: unless-stopped

  inference_model_server:
    image: onyxdotapp/onyx-model-server:craft-latest
    container_name: onyx-inference
    command: >
      /bin/sh -c "exec uvicorn model_server.main:app --host 0.0.0.0 --port 9000"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9000/api/health')"]
      interval: 20s
      timeout: 5s
      retries: 3
    volumes:
      - onyx_model_cache:/app/.cache/huggingface/
    networks:
      - ollama-network
    restart: unless-stopped

  indexing_model_server:
    image: onyxdotapp/onyx-model-server:craft-latest
    container_name: onyx-indexing
    command: >
      /bin/sh -c "exec uvicorn model_server.main:app --host 0.0.0.0 --port 9000"
    environment:
      INDEXING_ONLY: "True"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9000/api/health')"]
      interval: 20s
      timeout: 5s
      retries: 3
    volumes:
      - onyx_indexing_cache:/app/.cache/huggingface/
    networks:
      - ollama-network
    restart: unless-stopped

  api_server:
    image: onyxdotapp/onyx-backend:craft-latest
    container_name: onyx-api
    command: >
      /bin/sh -c "alembic upgrade head &&
      echo 'Starting Onyx Api Server' &&
      uvicorn onyx.main:app --host 0.0.0.0 --port 8080"
    env_file:
      - ../.env
    environment:
      <<: *onyx-env
      USE_LIGHTWEIGHT_BACKGROUND_WORKER: "true"
    depends_on:
      relational_db:
        condition: service_started
      index:
        condition: service_started
      cache:
        condition: service_started
      inference_model_server:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - onyx_file_system:/app/file-system
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health')"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    networks:
      - ollama-network
    restart: unless-stopped

  background:
    image: onyxdotapp/onyx-backend:craft-latest
    container_name: onyx-background
    command: >
      /bin/sh -c "
      if [ -f /app/scripts/setup_craft_templates.sh ]; then /app/scripts/setup_craft_templates.sh; fi &&
      /app/scripts/supervisord_entrypoint.sh
      "
    env_file:
      - ../.env
    environment:
      <<: *onyx-env
      USE_LIGHTWEIGHT_BACKGROUND_WORKER: "true"
      API_SERVER_PROTOCOL: http
      API_SERVER_HOST: api_server
    depends_on:
      - relational_db
      - index
      - cache
      - inference_model_server
      - indexing_model_server
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - onyx_file_system:/app/file-system
    networks:
      - ollama-network
    restart: unless-stopped

  web_server:
    image: onyxdotapp/onyx-web-server:craft-latest
    container_name: onyx-web
    env_file:
      - ../.env
    environment:
      INTERNAL_URL: http://api_server:8080
    depends_on:
      api_server:
        condition: service_healthy
    networks:
      - ollama-network
    restart: unless-stopped

  onyx-nginx:
    image: nginx:1.25.5-alpine
    container_name: onyx-nginx
    volumes:
      - ./onyx/nginx/app.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - api_server
      - web_server
    networks:
      - ollama-network
    restart: unless-stopped

volumes:
  onyx_db:
  onyx_vespa:
  onyx_model_cache:
  onyx_indexing_cache:
  onyx_file_system:

networks:
  ollama-network:
    external: true
